import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import classification_report
from sklearn.preprocessing import StandardScaler
import joblib
import os
import glob

# --- è¨­å®š ---
DATA_DIR = "./emg_data_svm/"
MODEL_FILE_RADIAL = "svm_radial_binary.joblib"  # Radialãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚¡ã‚¤ãƒ«å
SCALER_FILE_RADIAL = "scaler_radial_binary.joblib"  # Radialã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼
MODEL_FILE_ULNAR = "svm_ulnar_binary.joblib"  # Ulnarãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚¡ã‚¤ãƒ«å
SCALER_FILE_ULNAR = "scaler_ulnar_binary.joblib"  # Ulnarã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼

WINDOW_SIZE = 10
M_SAMPLES = 10

# ğŸŒŸ ãƒãƒ£ãƒ³ãƒãƒ«ã®åˆ†é›¢
ALL_CHANNELS = [2, 3, 6, 7]
RADIAL_CHANNELS = [2, 3]  # Radial Devå°‚ç”¨ãƒãƒ£ãƒ³ãƒãƒ«
ULNAR_CHANNELS = [6, 7]  # Ulnar Devå°‚ç”¨ãƒãƒ£ãƒ³ãƒãƒ«

# ãƒ©ãƒ™ãƒ«å¤‰æ›ãƒãƒƒãƒ—
LABEL_MAP = {
    "rest": 0,
    "radial_dev": 1,
    "ulnar_dev": 2,
}
REVERSE_LABEL_MAP = {v: k for k, v in LABEL_MAP.items()}

# â˜… RBFã‚«ãƒ¼ãƒãƒ«è¨­å®š
SVM_GAMMA = 0.1
SVM_C = 0.01


# --- ç‰¹å¾´é‡æŠ½å‡ºé–¢æ•° (WLè¿½åŠ ç‰ˆ) ---
def extract_features(data, window_size, M, feature_cols):
    """RMS, DeltaRMS, WLã®12æ¬¡å…ƒç‰¹å¾´é‡ã‚’æŠ½å‡ºã™ã‚‹ï¼ˆãƒãƒ£ãƒãƒ«æŒ‡å®šå¯èƒ½ï¼‰"""
    N_samples = len(data)
    features = []

    start_index = M + window_size - 1

    for i in range(start_index, N_samples):
        current_window_signal = data.iloc[i - window_size + 1 : i + 1][feature_cols]
        past_window_signal = data.iloc[i - window_size + 1 - M : i + 1 - M][
            feature_cols
        ]

        feature_vector = []

        # 1. çµ¶å¯¾RMS (R_k)
        rms = np.sqrt(np.mean(current_window_signal**2, axis=0))
        feature_vector.extend(rms.tolist())

        # 2. å·®åˆ†RMS (Î”R_k)
        rms_past = np.sqrt(np.mean(past_window_signal**2, axis=0))
        delta_rms = rms - rms_past
        feature_vector.extend(delta_rms.tolist())

        # 3. WL (Waveform Length)
        wl_list = []
        for col in feature_cols:
            signal = current_window_signal[col].values
            wl = np.sum(np.abs(np.diff(signal)))
            wl_list.append(wl)

        feature_vector.extend(wl_list)
        features.append(feature_vector)

    labels_series = data["Label"].iloc[start_index:].values

    return np.array(features), labels_series


# --- è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰é–¢æ•° (å¤‰æ›´ãªã—) ---
def load_data_from_directory(data_dir, channels, label_map):
    # ... (ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰é–¢æ•°ã¯çœç•¥ã—ã€ä»¥å‰ã®ã‚‚ã®ã¨åŒã˜ã¨ã—ã¾ã™) ...
    all_emg_data = []
    csv_files = glob.glob(os.path.join(data_dir, "*.csv"))

    if not csv_files:
        print(f"ã‚¨ãƒ©ãƒ¼: {data_dir} å†…ã«CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return None

    print(f"âœ… {len(csv_files)}å€‹ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã™...")

    for file_path in csv_files:
        try:
            df = pd.read_csv(file_path)
            channel_cols = [f"CH{c}" for c in channels]
            required_cols = channel_cols + ["Label"]

            if not all(col in df.columns for col in required_cols):
                print(
                    f"è­¦å‘Š: {file_path} ã«å¿…è¦ãªã‚«ãƒ©ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚"
                )
                continue

            df_selected = df[required_cols].copy()
            df_selected["Label"] = df_selected["Label"].map(label_map)
            df_selected.dropna(subset=["Label"], inplace=True)
            df_selected["Label"] = df_selected["Label"].astype(int)
            all_emg_data.append(df_selected)

        except Exception as e:
            print(f"ãƒ•ã‚¡ã‚¤ãƒ« {file_path} ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            continue

    if not all_emg_data:
        print("ã‚¨ãƒ©ãƒ¼: æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒæŠ½å‡ºã•ã‚ŒãŸCSVãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        return None

    return pd.concat(all_emg_data, ignore_index=True)


# --- ğŸŒŸ æœ€çµ‚åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯ (æ¨è«–é–¢æ•°) ---
def predict_parallel(score_rad, score_uln, rest_label=LABEL_MAP["rest"]):
    """
    ä¸¦åˆ—åˆ†é¡å™¨ã®æ±ºå®šã‚¹ã‚³ã‚¢ã‚’çµ±åˆã—ã€æœ€çµ‚ãƒ©ãƒ™ãƒ«ã‚’æ±ºå®šã™ã‚‹ã€‚
    ã‚¹ã‚³ã‚¢ã¯SVMã®decision_function (ãƒã‚¤ãƒ‘ãƒ¼ãƒ—ãƒ¬ãƒ¼ãƒ³ã‹ã‚‰ã®è·é›¢) ã‚’ä½¿ç”¨ã™ã‚‹ã€‚
    """
    y_pred = np.full(len(score_rad), rest_label)  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯rest (0)

    # 1. radial_dev ã®ã‚¹ã‚³ã‚¢ãŒé«˜ã„å ´åˆ
    # score_rad > score_uln (ä»–ã®å‹•ä½œã‚ˆã‚Šæ’“å±ˆã®ç¢ºä¿¡åº¦ãŒé«˜ã„)
    # ã‹ã¤ score_rad > 0 (æ’“å±ˆã¨äºˆæ¸¬ã•ã‚ŒãŸç©ºé–“ã«ã‚ã‚‹)
    # Ulnarã®ã‚¹ã‚³ã‚¢ã‚‚è€ƒæ…®ã—ã€æ‹®æŠ—ã—ã¦ã„ã‚‹å ´åˆã¯restã«ã™ã‚‹

    # ğŸŒŸ åˆ¤å®šé–¾å€¤ (C=0.1ã®å ´åˆã€æ±ºå®šå¢ƒç•Œã¯0ã ãŒã€ãƒã‚¤ã‚ºå¯¾ç­–ã§å°‘ã—ä½™è£•ã‚’æŒãŸã›ã‚‹)
    # ã“ã“ã§ã¯å˜ç´”ã« 0 ã‚’ä½¿ç”¨ã—ã¾ã™
    THRESHOLD = -0.5

    # æ’“å±ˆã¨äºˆæ¸¬ã™ã‚‹æ¡ä»¶
    is_radial = (score_rad > THRESHOLD) & (score_rad > score_uln)

    # å°ºå±ˆã¨äºˆæ¸¬ã™ã‚‹æ¡ä»¶
    is_ulnar = (score_uln > THRESHOLD) & (
        score_uln >= score_rad
    )  # >= ã¯ã‚¹ã‚³ã‚¢ãŒç­‰ã—ã„å ´åˆã«å°ºå±ˆã‚’å„ªå…ˆ (ä»»æ„)

    # ãƒ©ãƒ™ãƒ«ã‚’æ›´æ–°
    y_pred[is_radial] = LABEL_MAP["radial_dev"]
    y_pred[is_ulnar] = LABEL_MAP["ulnar_dev"]

    # ä¸¡æ–¹ã®ã‚¹ã‚³ã‚¢ãŒé–¾å€¤ã‚ˆã‚Šä½ã„å ´åˆã€ã¾ãŸã¯ã‚¹ã‚³ã‚¢ãŒéå¸¸ã«è¿‘ã„å ´åˆã¯ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®restã®ã¾ã¾ã¨ãªã‚‹ã€‚
    # ä¾‹: score_rad=0.5, score_uln=0.6 ã®å ´åˆã€ulnar_dev ã«åˆ†é¡ã•ã‚Œã‚‹ã€‚
    # ä¾‹: score_rad=-0.1, score_uln=-0.2 ã®å ´åˆã€rest ã«åˆ†é¡ã•ã‚Œã‚‹ã€‚

    return y_pred


# --- ãƒ¡ã‚¤ãƒ³å­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹ ---
def train_model():
    # 1. ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰ã¨ç‰¹å¾´é‡æŠ½å‡º
    combined_df = load_data_from_directory(DATA_DIR, ALL_CHANNELS, LABEL_MAP)
    if combined_df is None:
        return

    # å…¨ãƒãƒ£ãƒ³ãƒãƒ«ã®ç‰¹å¾´é‡ (RMS, DeltaRMS, WL) ã‚’æŠ½å‡º
    emg_cols = [f"CH{c}" for c in ALL_CHANNELS]
    X, y = extract_features(combined_df, WINDOW_SIZE, M_SAMPLES, feature_cols=emg_cols)

    feature_names = [f"{t}_{c}" for t in ["RMS", "DeltaRMS", "WL"] for c in emg_cols]

    print(f"ç‰¹å¾´é‡æŠ½å‡ºå¾Œã®ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(X)}")
    print(f"ç”Ÿæˆã•ã‚ŒãŸç‰¹å¾´é‡ ({len(feature_names)}æ¬¡å…ƒ): {', '.join(feature_names)}")

    # 2. å­¦ç¿’/ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿åˆ†å‰²
    X_train_full, X_test_full, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    print(f"\nå­¦ç¿’ãƒ‡ãƒ¼ã‚¿æ•°: {len(X_train_full)}, ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿æ•°: {len(X_test_full)}")

    # 3. ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™ã¨ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’

    # --- Radial Dev ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ ---
    print("\n--- Radial Dev (CH2, CH3) ãƒ¢ãƒ‡ãƒ«å­¦ç¿’é–‹å§‹ ---")

    # Radial Dev ã«å¿…è¦ãªç‰¹å¾´é‡ã‚«ãƒ©ãƒ ã‚’é¸æŠ
    rad_features = [
        name for name in feature_names if any(f"CH{c}" in name for c in RADIAL_CHANNELS)
    ]

    # X_train_fullã‹ã‚‰Radialç‰¹å¾´é‡ã®ã¿ã‚’æŠ½å‡º
    df_train_full = pd.DataFrame(X_train_full, columns=feature_names)
    X_rad_train_raw = df_train_full[rad_features].values

    # ãƒ©ãƒ™ãƒ«ã‚’ãƒã‚¤ãƒŠãƒªã«å¤‰æ›: radial_dev(1) vs other(0)
    y_rad_train = np.where(y_train == LABEL_MAP["radial_dev"], 1, 0)

    # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
    scaler_rad = StandardScaler()
    X_rad_train = scaler_rad.fit_transform(X_rad_train_raw)

    # ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
    svm_rad = SVC(
        kernel="rbf", C=SVM_C, gamma=SVM_GAMMA, random_state=42, probability=False
    )  # decision_functionã‚’ä½¿ç”¨ã™ã‚‹ãŸã‚probability=False
    svm_rad.fit(X_rad_train, y_rad_train)

    joblib.dump(svm_rad, MODEL_FILE_RADIAL)
    joblib.dump(scaler_rad, SCALER_FILE_RADIAL)
    print(f"âœ… Radial Dev ãƒ¢ãƒ‡ãƒ«ã¨ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ã‚’ä¿å­˜: {MODEL_FILE_RADIAL}")

    # --- Ulnar Dev ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ ---
    print("\n--- Ulnar Dev (CH6, CH7) ãƒ¢ãƒ‡ãƒ«å­¦ç¿’é–‹å§‹ ---")

    # Ulnar Dev ã«å¿…è¦ãªç‰¹å¾´é‡ã‚«ãƒ©ãƒ ã‚’é¸æŠ
    uln_features = [
        name for name in feature_names if any(f"CH{c}" in name for c in ULNAR_CHANNELS)
    ]

    # X_train_fullã‹ã‚‰Ulnarç‰¹å¾´é‡ã®ã¿ã‚’æŠ½å‡º
    X_uln_train_raw = df_train_full[uln_features].values

    # ãƒ©ãƒ™ãƒ«ã‚’ãƒã‚¤ãƒŠãƒªã«å¤‰æ›: ulnar_dev(1) vs other(0)
    y_uln_train = np.where(y_train == LABEL_MAP["ulnar_dev"], 1, 0)

    # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
    scaler_uln = StandardScaler()
    X_uln_train = scaler_uln.fit_transform(X_uln_train_raw)

    # ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
    svm_uln = SVC(
        kernel="rbf", C=SVM_C, gamma=SVM_GAMMA, random_state=42, probability=False
    )
    svm_uln.fit(X_uln_train, y_uln_train)

    joblib.dump(svm_uln, MODEL_FILE_ULNAR)
    joblib.dump(scaler_uln, SCALER_FILE_ULNAR)
    print(f"âœ… Ulnar Dev ãƒ¢ãƒ‡ãƒ«ã¨ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ã‚’ä¿å­˜: {SCALER_FILE_ULNAR}")

    # 4. è©•ä¾¡ (ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿)
    print("\n--- ä¸¦åˆ—åˆ†é¡å™¨ã«ã‚ˆã‚‹è©•ä¾¡é–‹å§‹ ---")

    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç‰¹å¾´é‡ã‚’æŠ½å‡ºã—ã€ãã‚Œãã‚Œã®ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ã§æ­£è¦åŒ–
    df_test_full = pd.DataFrame(X_test_full, columns=feature_names)

    X_rad_test_raw = df_test_full[rad_features].values
    X_rad_test = scaler_rad.transform(X_rad_test_raw)

    X_uln_test_raw = df_test_full[uln_features].values
    X_uln_test = scaler_uln.transform(X_uln_test_raw)

    # å„ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰æ±ºå®šé–¢æ•°ã‚¹ã‚³ã‚¢ã‚’å–å¾—
    score_rad = svm_rad.decision_function(X_rad_test)
    score_uln = svm_uln.decision_function(X_uln_test)

    # æœ€çµ‚åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯ã‚’é©ç”¨
    y_pred_combined = predict_parallel(score_rad, score_uln)

    # è©•ä¾¡ãƒ¬ãƒãƒ¼ãƒˆ
    print("\n--- Classification Report (ä¸¦åˆ—åˆ†é¡å™¨çµ±åˆçµæœ) ---")
    target_names = [REVERSE_LABEL_MAP[val] for val in sorted(REVERSE_LABEL_MAP.keys())]
    print(
        classification_report(
            y_test, y_pred_combined, target_names=target_names, zero_division=0
        )
    )

    print("\n--- å®Œäº†: 2ã¤ã®ãƒ¢ãƒ‡ãƒ«ã¨ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ãŒä¿å­˜ã•ã‚Œã¾ã—ãŸ ---")


if __name__ == "__main__":
    train_model()
